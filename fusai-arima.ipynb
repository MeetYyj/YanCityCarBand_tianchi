{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pylab as plt\n",
    "import config as cf\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARMA, ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style()\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix_df = pd.read_csv(cf.train_fix_file_path)\n",
    "fs_train_df = pd.read_csv(cf.fusai_train_file_path, sep='\\t')\n",
    "# A\n",
    "fs_testA_df = pd.read_csv(cf.fusai_testA_file_path, sep='\\t')\n",
    "# B\n",
    "fs_testB_df = pd.read_csv(cf.fusai_testB_file_path, sep='\\t')\n",
    "\n",
    "# fs_test_df = fs_testA_df\n",
    "fs_test_df = fs_testA_df\n",
    "\n",
    "# predict by arima.ipynb\n",
    "predict_fix_df = pd.read_csv('test_fix.csv')\n",
    "predict_fix_df = predict_fix_df.rename(columns={'predict':'cnt'})\n",
    "\n",
    "# convert to datetime\n",
    "train_fix_df.loc[:,'date_fix'] = pd.to_datetime(train_fix_df['date_fix'])\n",
    "predict_fix_df.loc[:,'date_fix'] = pd.to_datetime(predict_fix_df['date_fix'])\n",
    "\n",
    "# normalize\n",
    "train_fix_df = train_fix_df.drop(['Unnamed: 0'], axis=1)\n",
    "predict_fix_df.loc[:,'month'] = predict_fix_df.loc[:, 'date_fix'].map(lambda x: datetime(x.year,x.month,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(24,3))\n",
    "ax1 = f.add_subplot(111)\n",
    "fs_train_brand_df = fs_train_df.groupby('brand', as_index=False)\n",
    "for frame in fs_train_brand_df:\n",
    "    frame[1].loc[:,\"cnt\"].plot(ax = ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data_date(df, last_dow, start_date):\n",
    "    fix_rows = []\n",
    "    fix_date = 0\n",
    "    fix_columns = np.append(df.columns.values, 'date_fix')\n",
    "    is_train = 'cnt' in fix_columns\n",
    "    for i, row in df.iterrows():\n",
    "        curr_dow = row['day_of_week']\n",
    "        while curr_dow - last_dow > 1 or -6 < curr_dow - last_dow <= 0:\n",
    "            last_dow = last_dow + 1 if last_dow < 7 else 1\n",
    "            fix_date += 1\n",
    "            if is_train:\n",
    "                fix_rows.append(np.array([-1, 0, last_dow, start_date + timedelta(days=fix_date)]))\n",
    "            else:\n",
    "                fix_rows.append(np.array([-1, last_dow, start_date + timedelta(days=fix_date)]))\n",
    "        last_dow = curr_dow\n",
    "        fix_date += 1\n",
    "        fix_rows.append(np.append(row.values, start_date + timedelta(days=fix_date)))\n",
    "    new_df = pd.DataFrame(fix_rows, columns=fix_columns)\n",
    "    return new_df\n",
    "\n",
    "# process train date\n",
    "start_train_date = datetime(2012,12,31)\n",
    "fs_train_cnt_df = fs_train_df.groupby('date', as_index=False)['cnt'].sum()\n",
    "fs_train_cnt_df = fs_train_cnt_df.merge(fs_train_df[['date', 'day_of_week']].drop_duplicates(), on='date')\n",
    "fs_train_new_df = fix_data_date(fs_train_cnt_df, 1, start_train_date)\n",
    "# process test date\n",
    "start_test_date = fs_train_new_df.iloc[-1,-1] - timedelta(days=1)\n",
    "last_dow = fs_train_new_df.iloc[-1,-2] - 1\n",
    "fs_test_cnt_df = fs_test_df[['date', 'day_of_week']].drop_duplicates()\n",
    "fs_test_new_df = fix_data_date(fs_test_cnt_df, last_dow, start_test_date)\n",
    "# A\n",
    "##test_new_df = test_new_df.append(pd.DataFrame([[-1,3,datetime(2017,3,1)]], columns=test_new_df.columns.values))\n",
    "# B\n",
    "#test_new_df = test_new_df.append(pd.DataFrame([[-1,3,datetime(2017,11,29)]], columns=test_new_df.columns.values))\n",
    "#test_new_df = test_new_df.append(pd.DataFrame([[-1,4,datetime(2017,11,30)]], columns=test_new_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_train_new_df.to_csv(cf.fusai_train_fix_file_path)\n",
    "\n",
    "f = plt.figure(figsize=(24,3))\n",
    "ax1 = f.add_subplot(111)\n",
    "fs_train_new_df[['cnt']].plot(ax=ax1)\n",
    "train_fix_df[['cnt']].plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2016-01-05'\n",
    "end_date = '2016-05-06'\n",
    "\n",
    "fs = fs_train_new_df.loc[fs_train_new_df['date_fix'] > start_date].sum()['cnt']\n",
    "cs = train_fix_df.loc[(train_fix_df['date_fix'] > start_date) & (train_fix_df['date_fix'] < end_date)].sum()['cnt']\n",
    "factor = float(fs) / cs\n",
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_num = fs_train_new_df.loc[fs_train_new_df['date_fix'] == start_date]\n",
    "start_date_num = start_date_num.iloc[0][0]\n",
    "print start_date_num\n",
    "\n",
    "brand_factors = fs_train_df.loc[fs_train_df['date'] > start_date_num].groupby('brand', as_index=False).sum()[['brand', 'cnt']]\n",
    "brand_factors.loc[:,'factor'] = brand_factors.loc[:,'cnt'] / fs\n",
    "brand_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predict result 0225\n",
    "predict_base_df = train_fix_df.append(predict_fix_df.loc[predict_fix_df['date_fix'] > train_fix_df.iloc[-1,3]])\n",
    "# cnt\n",
    "fs_test_new_df.loc[:,'date_fix'] = fs_test_new_df.loc[:,'date_fix'].astype(str)\n",
    "predict_base_df.loc[:,'date_fix'] = predict_base_df.loc[:,'date_fix'].astype(str)\n",
    "fs_test_cnt_df = fs_test_new_df.merge(predict_base_df[['date_fix', 'cnt']], how='left', on='date_fix')\n",
    "fs_test_cnt_df.loc[:, 'cnt'] = fs_test_cnt_df.loc[:, 'cnt'] * factor\n",
    "# brand cnt\n",
    "fs_test_ret_df = fs_test_df.merge(fs_test_cnt_df[['date', 'cnt']], how='left', on='date')\n",
    "fs_test_ret_df = fs_test_ret_df.merge(brand_factors[['brand', 'factor']], how='left', on='brand')\n",
    "fs_test_ret_df.loc[:, 'predict'] = fs_test_ret_df.loc[:, 'cnt'] * fs_test_ret_df.loc[:, 'factor'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_test_ret_df.to_csv('fs_testA_fix.csv')\n",
    "fs_test_ret_df[['date', 'brand', 'predict']].astype(int).to_csv('fs_testA.csv', sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
