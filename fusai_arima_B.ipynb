{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pylab as plt\n",
    "import config as cf\n",
    "import math\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARMA, ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style()\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步，预测品牌合计算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cf.fusai_train_file_path, sep='\\t')\n",
    "# A\n",
    "testA_df = pd.read_csv(cf.fusai_testA_file_path, sep='\\t')\n",
    "# B\n",
    "testB_df = pd.read_csv(cf.fusai_testB_file_path, sep='\\t')\n",
    "test_df = testB_df\n",
    "test_all_df = test_df[['date', 'day_of_week']].drop_duplicates()\n",
    "# answer A as train data\n",
    "trainA_df = pd.read_csv(cf.fusai_answerA_file_path, sep='\\t', header=None, names=['date', 'brand', 'cnt'])\n",
    "trainA_df = testA_df.merge(trainA_df)\n",
    "train_df = train_df.append(trainA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data_date(df, last_dow, start_date):\n",
    "    fix_rows = []\n",
    "    fix_date = 0\n",
    "    fix_columns = np.append(df.columns.values, 'date_fix')\n",
    "    is_train = 'cnt' in fix_columns\n",
    "    for i, row in df.iterrows():\n",
    "        curr_dow = row['day_of_week']\n",
    "        while curr_dow - last_dow > 1 or -6 < curr_dow - last_dow <= 0:\n",
    "            last_dow = last_dow + 1 if last_dow < 7 else 1\n",
    "            fix_date += 1\n",
    "            if is_train:\n",
    "                fix_rows.append(np.array([-1, 0, last_dow, start_date + timedelta(days=fix_date)]))\n",
    "            else:\n",
    "                fix_rows.append(np.array([-1, last_dow, start_date + timedelta(days=fix_date)]))\n",
    "        last_dow = curr_dow\n",
    "        fix_date += 1\n",
    "        fix_rows.append(np.append(row.values, start_date + timedelta(days=fix_date)))\n",
    "    new_df = pd.DataFrame(fix_rows, columns=fix_columns)\n",
    "    return new_df\n",
    "\n",
    "# process train date\n",
    "start_train_date = datetime(2012,12,31)\n",
    "train_cnt_df = train_df.groupby('date', as_index=False)['cnt'].sum()\n",
    "train_cnt_df = train_cnt_df.merge(train_df[['date', 'day_of_week']].drop_duplicates(), on='date')\n",
    "train_new_df = fix_data_date(train_cnt_df, 1, start_train_date)\n",
    "# process test date\n",
    "start_test_date = train_new_df.iloc[-1,-1] - timedelta(days=1)\n",
    "last_dow = train_new_df.iloc[-1,-2] - 1\n",
    "test_new_df = fix_data_date(test_all_df, last_dow, start_test_date)\n",
    "\n",
    "# test_new_df = test_new_df.append(pd.DataFrame([[-1,3,datetime(2017,11,29)]], columns=test_new_df.columns.values))\n",
    "# test_new_df = test_new_df.append(pd.DataFrame([[-1,4,datetime(2017,11,30)]], columns=test_new_df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. devide raw data into month trend and daily factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process train data\n",
    "train_new_df['month'] = train_new_df['date_fix'].map(lambda x:datetime(x.year,x.month,1))\n",
    "train_fix_df = train_new_df.loc[train_new_df['month'] < '20161001']\n",
    "frame_sum = train_fix_df.groupby('month')['cnt'].sum()\n",
    "frame_sum.name = 'month_sum'\n",
    "frame_days = train_fix_df.loc[train_fix_df['date']>0].groupby('month')['date'].count()\n",
    "frame_days.name = 'month_days'\n",
    "frame_mean = frame_sum / frame_days\n",
    "frame_mean.name = 'month_mean'\n",
    "train_fix_df = train_fix_df.merge(frame_sum.reset_index(), on='month')\n",
    "train_fix_df = train_fix_df.merge(frame_days.reset_index(), on='month')\n",
    "train_fix_df = train_fix_df.merge(frame_mean.reset_index(), on='month')\n",
    "train_fix_df.to_csv(cf.train_fix_file_path)\n",
    "train_fix_df.set_index('date_fix', inplace=True)\n",
    "# process test data\n",
    "test_new_df['month'] = test_new_df['date_fix'].map(lambda x:datetime(x.year,x.month,1))\n",
    "test_fix_df = test_new_df\n",
    "test_fix_df.to_csv(cf.test_fix_file_path)\n",
    "frame_days = test_fix_df.loc[test_fix_df['date']>0].groupby('month')['date'].count()\n",
    "frame_days.name = 'month_days'\n",
    "# fix last day\n",
    "# A\n",
    "#frame_days[-1] = 21\n",
    "test_fix_df = test_fix_df.merge(frame_days.reset_index(), on='month', how='left')\n",
    "test_fix_df.set_index('date_fix', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. First Predict monthly trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一月数据缺失\n",
    "ts = frame_mean.diff(12)\n",
    "# diff修正值\n",
    "diff_plus = 1 - ts.min()\n",
    "# deal with neg values and use log to reduce amplitude\n",
    "ts = np.log(ts + diff_plus)\n",
    "ts.dropna(inplace=True)\n",
    "# fix sample with huge diff\n",
    "#ts[4] = 6\n",
    "#ts[13] = 7.0\n",
    "#ts[32] = 5.8\n",
    "ts.plot()\n",
    "\n",
    "f = plt.figure()\n",
    "ax1 = f.add_subplot(211)\n",
    "plot_acf(ts, lags=24, ax=ax1)\n",
    "ax2 = f.add_subplot(212)\n",
    "plot_pacf(ts, lags=24, ax=ax2)\n",
    "\n",
    "print adfuller(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "f = plt.figure(figsize=(24,12))\n",
    "ax1 = f.add_subplot(211)\n",
    "#ax2 = f.add_subplot(212)\n",
    "model = ARMA(ts, order=(6, 6)) \n",
    "result_arma = model.fit(disp=-1)\n",
    "#result_arma.plot_predict(start='2014-08-01', ax=ax1)\n",
    "print result_arma.summary()\n",
    "\n",
    "# recover predict value\n",
    "predict_values = result_arma.predict(end='2017-12-1')\n",
    "# log recover\n",
    "predict_values = np.exp(predict_values) - diff_plus\n",
    "\n",
    "predict_values.plot()\n",
    "frame_mean.diff(12).plot()\n",
    "\n",
    "\n",
    "frame_mean_ext = frame_mean.append(pd.Series(index=pd.date_range('2016-10','2017-09',freq='MS')))\n",
    "# calculate feature 2 years month brand value.\n",
    "pred_ts1 = (frame_mean_ext.shift(12) + predict_values).dropna()\n",
    "frame_mean_ext = pred_ts1.append(pd.Series(index=pd.date_range('2017-10','2018-09',freq='MS')))\n",
    "pred_ts2 = (frame_mean_ext.shift(12) + predict_values).dropna()\n",
    "\n",
    "frame_mean.plot()\n",
    "pred_ts = pred_ts1.append(pred_ts2.loc[pred_ts2.index>='2017-10'])\n",
    "pred_ts[pred_ts.index>='2016-09'].plot()\n",
    "pred_ts = frame_mean.append(pred_ts.loc[pred_ts.index>='2016-10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. predict daily factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    # add month infos.\n",
    "    df.loc[:,'month_of_year'] = df.index.map(lambda x: x.month)\n",
    "    df.loc[:,'day_of_month'] = df.index.map(lambda x: 1 if x.day < 11 else 2 if x.day < 21 else 3)\n",
    "    # add holiday infos.\n",
    "    df.loc[:,'is_holiday'] = df.index.map(lambda x: 1 if is_holiday(x.date()) else 0)\n",
    "    df.loc[:,'is_day_off'] = df[['is_holiday','day_of_week']].apply(lambda x: 1 if not x[0] and x[1] > 5 else 0, axis=1)\n",
    "    ext_feature_list = ['after_holiday', 'after_holiday_1', 'after_holiday_2',\n",
    "                        'before_holiday', 'before_holiday_1', 'before_holiday_2']\n",
    "    df = df.join(pd.DataFrame(0, df.index, ext_feature_list))\n",
    "    last_holidays = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['is_holiday']:\n",
    "            last_holidays += 1\n",
    "        else:\n",
    "            # law holiday\n",
    "            if last_holidays > 2:\n",
    "                holiday_long = 1 if last_holidays > 3 else 0.5\n",
    "                df.loc[index, 'after_holiday'] = holiday_long\n",
    "                before_index = index - timedelta(days=last_holidays + 1)\n",
    "                if before_index in df.index:\n",
    "                    df.loc[before_index, 'before_holiday'] = holiday_long\n",
    "                i = 1\n",
    "                after_ext_index = index + timedelta(days=1)\n",
    "                while i < 3 and after_ext_index in df.index:\n",
    "                    if df.loc[after_ext_index, 'is_holiday']:\n",
    "                        after_ext_index = after_ext_index + timedelta(days=1)\n",
    "                        continue\n",
    "                    df.loc[after_ext_index, 'after_holiday_%d' % i] = holiday_long\n",
    "                    i += 1\n",
    "                    after_ext_index = after_ext_index + timedelta(days=1)\n",
    "                i = 1\n",
    "                before_ext_index = before_index - timedelta(days=1)\n",
    "                while i < 3 and before_ext_index in df.index:\n",
    "                    if df.loc[before_ext_index, 'is_holiday']:\n",
    "                        before_ext_index = before_ext_index - timedelta(days=1)\n",
    "                        continue\n",
    "                    df.loc[before_ext_index, 'before_holiday_%d' % i] = holiday_long\n",
    "                    i += 1\n",
    "                    before_ext_index = before_ext_index - timedelta(days=1)\n",
    "            last_holidays = 0\n",
    "    # day before holiday or after holiday infos\n",
    "    df = df.join(pd.get_dummies(df['day_of_week'], prefix='day_of_week'))\n",
    "    #df = df.join(pd.get_dummies(df['day_of_month'], prefix='day_of_month'))\n",
    "    #df = df.join(pd.get_dummies(((df['month_of_year'] + 1) / 2).astype(int), prefix='month_of_year'))\n",
    "    df = df.join(pd.get_dummies(df['month_of_year'], prefix='month_of_year'))\n",
    "    # add holiday type\n",
    "    frame = pd.Series(map(lambda x, a1, a2, a3, b1, b2, b3: 1 if x < 6 and (a1 or a2 or a3 or b1 or b2 or b3) else 0,\n",
    "                      df['month_of_year'], df['after_holiday'], df['after_holiday_1'], df['after_holiday_2'],\n",
    "                      df['before_holiday'], df['before_holiday_1'], df['before_holiday_2']))\n",
    "    frame.name = 'spring_festeval'\n",
    "    frame.index = df.index\n",
    "    df = df.join(frame)\n",
    "    frame = pd.Series(map(lambda x, a1, a2, a3, b1, b2, b3: 1 if x > 7 and (a1 or a2 or a3 or b1 or b2 or b3) else 0,\n",
    "                      df['month_of_year'], df['after_holiday'], df['after_holiday_1'], df['after_holiday_2'],\n",
    "                      df['before_holiday'], df['before_holiday_1'], df['before_holiday_2']))\n",
    "    frame.name = 'national_day'\n",
    "    frame.index = df.index\n",
    "    df = df.join(frame)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proc_df = process_features(train_fix_df)\n",
    "test_proc_df = process_features(test_fix_df)\n",
    "# labels\n",
    "train_proc_df.loc[:,'day_factor'] = train_proc_df['cnt'] / train_proc_df['month_mean']\n",
    "# date split\n",
    "train_valid_df = train_proc_df.iloc[train_proc_df.index < '2014']\n",
    "train_proc_df = train_proc_df.iloc[train_proc_df.index >= '2014']\n",
    "\n",
    "\n",
    "# 取出训练集的y\n",
    "train_y = train_proc_df.iloc[:,-1]\n",
    "train_X = train_proc_df.iloc[:,9:-1]\n",
    "test_X = test_proc_df.iloc[:,6:]\n",
    "valid_y = train_valid_df.iloc[:,-1]\n",
    "valid_X = train_valid_df.iloc[:,9:-1]\n",
    "\n",
    "max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 建立一个默认的xgboost回归模型\n",
    "reg = xgboost.XGBRegressor(max_depth=max_depth)\n",
    "reg.fit(train_X, train_y)\n",
    "xgboost.plot_importance(reg)\n",
    "xgboost.plot_tree(reg)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(120, 80)\n",
    "#fig.savefig('tree.png')\n",
    "# 验证\n",
    "y_pred= reg.predict(valid_X)\n",
    "frame = pd.Series(y_pred, index=valid_X.index)\n",
    "frame.map(lambda x:x if x > 0 else 0)\n",
    "frame.name = 'pred'\n",
    "#pred_df = test_X.join(pred_y)\n",
    "pred_df = train_fix_df.iloc[train_fix_df.index < '2014'].join(frame)\n",
    "\n",
    "frame_days = pred_df.groupby('month').sum()['pred']\n",
    "frame_days.name = 'month_days_pred'\n",
    "pred_df = pred_df.join(frame_days, on='month')\n",
    "#pred_df.loc[pred_df['month']=='2017-02-01', 'month_days'] = 14\n",
    "\n",
    "print \"MSE:\", mean_squared_error(valid_y * pred_df['month_mean'], frame * pred_df['month_mean'])\n",
    "print \"MSE:\", mean_squared_error(valid_y * pred_df['month_mean'] * pred_df['month_days'] / pred_df['month_days_pred'], frame * pred_df['month_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train weight\n",
    "reg1 = xgboost.XGBRegressor(max_depth=max_depth)\n",
    "reg1.fit(train_X.iloc[train_X.index<'2015'], train_y.iloc[train_y.index<'2015'])\n",
    "\n",
    "reg2 = xgboost.XGBRegressor(max_depth=max_depth)\n",
    "reg2.fit(train_X.iloc[train_X.index>='2015'], train_y.iloc[train_y.index>='2015'])\n",
    "\n",
    "y_pred1 = reg1.predict(valid_X)\n",
    "y_pred2 = reg2.predict(valid_X)\n",
    "y_pred = y_pred1 * 1 / 3 + y_pred2 * 2 / 3\n",
    "frame = pd.Series(y_pred, index=valid_X.index)\n",
    "frame.map(lambda x:x if x > 0 else 0)\n",
    "frame.name = 'pred'\n",
    "#pred_df = test_X.join(pred_y)\n",
    "pred_df = train_fix_df.iloc[train_fix_df.index < '2014'].join(frame)\n",
    "\n",
    "frame_days = pred_df.groupby('month').sum()['pred']\n",
    "frame_days.name = 'month_days_pred'\n",
    "pred_df = pred_df.join(frame_days, on='month')\n",
    "#pred_df.loc[pred_df['month']=='2017-02-01', 'month_days'] = 14\n",
    "\n",
    "print \"MSE:\", mean_squared_error(valid_y * pred_df['month_mean'], frame * pred_df['month_mean'])\n",
    "print \"MSE:\", mean_squared_error(valid_y * pred_df['month_mean'] * pred_df['month_days'] / pred_df['month_days_pred'], frame * pred_df['month_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "y_pred = model.predict(valid_X)\n",
    "\n",
    "frame = pd.Series(y_pred, index=valid_X.index)\n",
    "frame.map(lambda x:x if x > 0 else 0)\n",
    "frame.name = 'pred'\n",
    "#pred_df = test_X.join(pred_y)\n",
    "pred_df = train_fix_df.iloc[train_fix_df.index < '2014'].join(frame)\n",
    "print \"MSE:\", mean_squared_error(valid_y * pred_df['month_mean'], frame * pred_df['month_mean'])\n",
    "\n",
    "#print pd.DataFrame(model.coef_, columns=train_X.columns.values)\n",
    "print train_X.columns.values\n",
    "print model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(train_X, train_y)\n",
    "y_pred = model.predict(valid_X)\n",
    "\n",
    "frame = pd.Series(y_pred, index=valid_X.index)\n",
    "frame.map(lambda x:x if x > 0 else 0)\n",
    "frame.name = 'pred'\n",
    "#pred_df = test_X.join(pred_y)\n",
    "pred_df = train_fix_df.iloc[train_fix_df.index < '2014'].join(frame)\n",
    "print \"MSE:\", mean_squared_error(valid_y * pred_df['month_mean'], frame * pred_df['month_mean'])\n",
    "\n",
    "#print pd.DataFrame(model.coef_, columns=train_X.columns.values)\n",
    "print train_X.columns.values\n",
    "#print model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 预测\n",
    "y_pred = reg.predict(test_X)\n",
    "frame_pred = pd.Series(y_pred, index=test_X.index)\n",
    "frame_pred.map(lambda x:x if x > 0 else 0)\n",
    "frame_pred.name = 'pred'\n",
    "#pred_df = test_X.join(pred_y)\n",
    "pred_df = test_fix_df.join(frame_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测 weight\n",
    "y_pred1 = reg1.predict(test_X)\n",
    "y_pred2 = reg2.predict(test_X)\n",
    "y_pred = y_pred1 * 1 / 3 + y_pred2 * 2 / 3\n",
    "frame_pred = pd.Series(y_pred, index=test_X.index)\n",
    "frame_pred.map(lambda x:x if x > 0 else 0)\n",
    "frame_pred.name = 'pred'\n",
    "#pred_df = test_X.join(pred_y)\n",
    "pred_df = test_fix_df.join(frame_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果组合\n",
    "frame = pred_ts\n",
    "frame.name = 'month_mean'\n",
    "pred_cb_df = pred_df.join(frame, on='month')\n",
    "\n",
    "#print pred_cb_df.groupby('month').sum()['pred']\n",
    "frame_days = pred_cb_df.loc[pred_cb_df['date']>0].groupby('month').sum()['pred']\n",
    "frame_days.name = 'month_days_pred'\n",
    "pred_cb_df = pred_cb_df.join(frame_days, on='month')\n",
    "\n",
    "pred_cb_df.loc[:, 'predict'] = pred_cb_df['month_mean'] * pred_cb_df['pred']\n",
    "# pred_cb_df.loc[:, 'predict'] = pred_cb_df['month_mean'] * pred_cb_df['pred'] * pred_cb_df['month_days'] / pred_cb_df['month_days_pred']\n",
    "pred_cb_df.loc[:, 'predict'] = pred_cb_df['predict'].map(lambda x:x if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_df.set_index('date_fix')['cnt'].plot(figsize=(32,3))\n",
    "pred_cb_df['predict'].plot(figsize=(32,3))\n",
    "pred_cb_df.loc[pred_cb_df['date']>0][['date', 'predict']].astype(int).to_csv('fs_temp.csv', sep='\\t', index=False, header=False)\n",
    "pred_cb_df[['date', 'day_of_week', 'predict']].to_csv('fs_temp_fix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cb_df[['month', 'month_days', 'month_days_pred']].drop_duplicates()\n",
    "train_proc_df['day_factor'].plot(figsize=(32,3))\n",
    "frame_pred.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二部，计算品牌数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict by arima.ipynb\n",
    "predict_fix_df = pd.read_csv('fs_temp_fix.csv')\n",
    "predict_fix_df = predict_fix_df.rename(columns={'predict':'cnt'})\n",
    "\n",
    "# convert to datetime\n",
    "predict_fix_df.loc[:,'date_fix'] = pd.to_datetime(predict_fix_df['date_fix'])\n",
    "\n",
    "# normalize\n",
    "predict_fix_df.loc[:,'month'] = predict_fix_df.loc[:, 'date_fix'].map(lambda x: datetime(x.year,x.month,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(24,3))\n",
    "ax1 = f.add_subplot(111)\n",
    "train_brand_df = train_df.groupby('brand', as_index=False)\n",
    "for frame in train_brand_df:\n",
    "    frame[1].loc[:,\"cnt\"].plot(ax = ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(24,3))\n",
    "ax1 = f.add_subplot(111)\n",
    "train_new_df[['date_fix', 'cnt']].set_index('date_fix').plot(ax=ax1)\n",
    "predict_fix_df[['date_fix','cnt']].set_index('date_fix').plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2016-07-11'\n",
    "end_date = '2016-10-12'\n",
    "fs = train_new_df.loc[train_new_df['date_fix'] > start_date].sum()['cnt']\n",
    "factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_num = train_new_df.loc[train_new_df['date_fix'] == start_date]\n",
    "start_date_num = start_date_num.iloc[0][0]\n",
    "print start_date_num\n",
    "\n",
    "brand_factors = train_df.loc[train_df['date'] > start_date_num].groupby('brand', as_index=False).sum()[['brand', 'cnt']]\n",
    "brand_factors.loc[:,'factor'] = brand_factors.loc[:,'cnt'] / fs\n",
    "brand_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predict result 0225\n",
    "# predict_base_df = train_fix_df.append(predict_fix_df.loc[predict_fix_df['date_fix'] > train_fix_df.iloc[-1,3]])\n",
    "predict_base_df = predict_fix_df\n",
    "# cnt\n",
    "test_new_df.loc[:,'date_fix'] = test_new_df.loc[:,'date_fix'].astype(str)\n",
    "predict_base_df.loc[:,'date_fix'] = predict_base_df.loc[:,'date_fix'].astype(str)\n",
    "test_cnt_df = test_new_df.merge(predict_base_df[['date_fix', 'cnt']], how='left', on='date_fix')\n",
    "test_cnt_df.loc[:, 'cnt'] = test_cnt_df.loc[:, 'cnt'] * factor\n",
    "# brand cnt\n",
    "test_ret_df = test_df.merge(test_cnt_df[['date', 'cnt', 'date_fix']], how='left', on='date')\n",
    "test_ret_df = test_ret_df.merge(brand_factors[['brand', 'factor']], how='left', on='brand')\n",
    "test_ret_df.loc[:, 'predict'] = test_ret_df.loc[:, 'cnt'] * test_ret_df.loc[:, 'factor'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ret_df.to_csv('fs_test_fix.csv')\n",
    "test_ret_df[['date', 'brand', 'predict']].astype(int).to_csv('fs_test.csv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testB_ret_df = test_ret_df.loc[test_ret_df['date'] >= 1250]\n",
    "\n",
    "testB_ret_df.to_csv('fs_testB_fix.csv')\n",
    "testB_ret_df[['date', 'brand', 'predict']].astype(int).to_csv('fs_testB.csv', sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
